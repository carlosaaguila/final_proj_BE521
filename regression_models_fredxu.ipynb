{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "from scipy.io import loadmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open leaderboard data\n",
    "leaderboard_data = loadmat('..\\\\leaderboard_data.mat')\n",
    "raw_training_data = loadmat('..\\\\raw_training_data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove data for training - per subject\n",
    "train_dg_s1 = raw_training_data['train_dg'][0][0]\n",
    "train_dg_s2 = raw_training_data['train_dg'][1][0]\n",
    "train_dg_s3 = raw_training_data['train_dg'][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dg_s1_downsample = train_dg_s1[::50][:-1]\n",
    "train_dg_s2_downsample = train_dg_s2[::50][:-1]\n",
    "train_dg_s3_downsample = train_dg_s3[::50][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_dg_s1_downsample.shape)\n",
    "# print(feats_s1_train.shape)\n",
    "# plt.scatter(feats_s1_train[:,[0:]], train_dg_s1_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_s1 = open(\"all_feats_s1_train_fx.npy\", \"rb\")\n",
    "feats_s1_train = np.load(file_s1)\n",
    "file_s1.close()\n",
    "\n",
    "file_s2 = open(\"all_feats_s2_train_fx.npy\", \"rb\")\n",
    "feats_s2_train = np.load(file_s2)\n",
    "file_s2.close()\n",
    "\n",
    "file_s3 = open(\"all_feats_s3_train_fx.npy\", \"rb\")\n",
    "feats_s3_train = np.load(file_s3)\n",
    "file_s3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds = np.random.choice(np.arange(0,len(feats_s1_train)), 4500, replace=False)\n",
    "selection_mask = np.zeros(len(feats_s1_train))\n",
    "selection_mask[train_inds] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 434)\n",
      "(1499, 434)\n",
      "(4500, 336)\n",
      "(1499, 336)\n",
      "(4500, 448)\n",
      "(1499, 448)\n"
     ]
    }
   ],
   "source": [
    "feats_s1_train_split = feats_s1_train[selection_mask.astype(bool)]\n",
    "feats_s1_valid_split = feats_s1_train[~selection_mask.astype(bool)]\n",
    "\n",
    "print(feats_s1_train_split.shape)\n",
    "print(feats_s1_valid_split.shape)\n",
    "\n",
    "feats_s2_train_split = feats_s2_train[selection_mask.astype(bool)]\n",
    "feats_s2_valid_split = feats_s2_train[~selection_mask.astype(bool)]\n",
    "\n",
    "print(feats_s2_train_split.shape)\n",
    "print(feats_s2_valid_split.shape)\n",
    "\n",
    "feats_s3_train_split = feats_s3_train[selection_mask.astype(bool)]\n",
    "feats_s3_valid_split = feats_s3_train[~selection_mask.astype(bool)]\n",
    "\n",
    "print(feats_s3_train_split.shape)\n",
    "print(feats_s3_valid_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_s1_train_split = train_dg_s1_downsample[selection_mask.astype(bool)]\n",
    "dg_s1_valid_split = train_dg_s1_downsample[~selection_mask.astype(bool)]\n",
    "\n",
    "dg_s2_train_split = train_dg_s2_downsample[selection_mask.astype(bool)]\n",
    "dg_s2_valid_split = train_dg_s2_downsample[~selection_mask.astype(bool)]\n",
    "\n",
    "\n",
    "dg_s3_train_split = train_dg_s3_downsample[selection_mask.astype(bool)]\n",
    "dg_s3_valid_split = train_dg_s3_downsample[~selection_mask.astype(bool)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=[100,200,100], activation='tanh', alpha=1e-5).fit(feats_s1_train_split, dg_s1_train_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(feats_s1_valid_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1105848999542174, 0.16378143852378532, 0.1902031888729781, 0.16138842421814187, 0.16834463288518295]\n"
     ]
    }
   ],
   "source": [
    "subj1_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred.transpose()[i]\n",
    "    finger_truth = dg_s1_valid_split.transpose()[i]\n",
    "    subj1_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj1_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_reg = RandomForestRegressor(n_estimators=1000).fit(feats_s1_train_split, dg_s1_train_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3628948124755439, 0.445706219652532, 0.3260761581038143, 0.37348195648853644, 0.3085596314587819]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = rfr_reg.predict(feats_s1_valid_split)\n",
    "\n",
    "subj1_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred.transpose()[i]\n",
    "    finger_truth = dg_s1_valid_split.transpose()[i]\n",
    "    subj1_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj1_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = 'subject1_rfr_1000.model'\n",
    "pickle.dump(rfr_reg, open(model_fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147500, 62)\n"
     ]
    }
   ],
   "source": [
    "leaderboard_data_s1 = leaderboard_data['leaderboard_ecog'][0][0]\n",
    "print(leaderboard_data_s1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3628948124755439, 0.445706219652532, 0.3260761581038143, 0.37348195648853644, 0.3085596314587819]\n"
     ]
    }
   ],
   "source": [
    "rfr_reg_loaded = pickle.load(open(model_fname, 'rb'))\n",
    "pred = rfr_reg_loaded.predict(feats_s1_valid_split)\n",
    "\n",
    "subj1_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred.transpose()[i]\n",
    "    finger_truth = dg_s1_valid_split.transpose()[i]\n",
    "    subj1_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj1_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBJECT 2\n",
    "rfr_reg_s2 = RandomForestRegressor(n_estimators=1000).fit(feats_s2_train_split, dg_s2_train_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5013905240357175, 0.3952314970935013, 0.44173697171067366, 0.47536595670923487, 0.41999721305827437]\n"
     ]
    }
   ],
   "source": [
    "pred2 = rfr_reg_s2.predict(feats_s2_valid_split)\n",
    "\n",
    "subj2_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred2.transpose()[i]\n",
    "    finger_truth = dg_s2_valid_split.transpose()[i]\n",
    "    subj2_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj2_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname_s2 = 'subject2_rfr_1000.model'\n",
    "pickle.dump(rfr_reg_s2, open(model_fname_s2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_reg_s3 = RandomForestRegressor(n_estimators=1000).fit(feats_s3_train_split, dg_s3_train_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5606863346069813, 0.4588151028936611, 0.43433989473331025, 0.552828754443724, 0.529255182645821]\n"
     ]
    }
   ],
   "source": [
    "pred3 = rfr_reg_s3.predict(feats_s3_valid_split)\n",
    "\n",
    "subj3_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred3.transpose()[i]\n",
    "    finger_truth = dg_s3_valid_split.transpose()[i]\n",
    "    subj3_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj3_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 5)\n",
      "[[-0.00501347  0.68820906  2.57802963  0.48578787  0.02674103]\n",
      " [-0.00501347  0.68820906  2.57802963  0.48578787  0.02674103]\n",
      " [-0.00501347  0.68820906  2.57802963  0.48578787  0.02674103]\n",
      " ...\n",
      " [-0.24686241 -0.94949675 -0.25215101 -0.45340061 -0.56300163]\n",
      " [-0.24658966 -0.94949961 -0.25224686 -0.45382118 -0.56321907]\n",
      " [-0.24631977 -0.94950056 -0.25234175 -0.45423698 -0.56343555]]\n",
      "(300000,)\n",
      "(300000,)\n",
      "(300000,)\n",
      "(300000,)\n",
      "(300000,)\n",
      "(300000,)\n",
      "(300000,)\n",
      "(300000,)\n",
      "(300000,)\n",
      "(300000,)\n",
      "[0.8978521447564057, 0.8819424136601375, 0.884203991853101, 0.8921962863843796, 0.8916418227539928]\n"
     ]
    }
   ],
   "source": [
    "pred3_all = rfr_reg_s3.predict(feats_s3_train)\n",
    "\n",
    "pred3_all_long = []\n",
    "for row in pred3_all:\n",
    "    for i in range(50):\n",
    "        pred3_all_long.append(row)\n",
    "        \n",
    "# It's short 50 entries, so add the last row 50 more times\n",
    "for i in range(50):\n",
    "    pred3_all_long.append(row)\n",
    "\n",
    "pred3_all_long = np.array(pred3_all_long)\n",
    "    \n",
    "subj3_corr = []\n",
    "print(pred3_all_long.shape)\n",
    "print(train_dg_s3)\n",
    "for i in range(5):\n",
    "    finger_pred = pred3_all_long.transpose()[i]\n",
    "    finger_truth = train_dg_s3.transpose()[i]\n",
    "    print(finger_pred.shape)\n",
    "    print(finger_truth.shape)\n",
    "    subj3_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj3_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname_s3 = 'subject3_rfr_1000.model'\n",
    "pickle.dump(rfr_reg_s3, open(model_fname_s3, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
