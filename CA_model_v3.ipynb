{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f018b75-ab8a-4608-a4e8-ea1461179975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import ellip, lfilter, filtfilt, find_peaks, butter, sosfiltfilt, sosfilt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "leaderboard_data = loadmat('/Users/carlosaguila/Downloads/drive-download-20220406T170639Z-001/leaderboard_data.mat')\n",
    "raw_training_data = loadmat('/Users/carlosaguila/Downloads/drive-download-20220406T170639Z-001/raw_training_data.mat')\n",
    "\n",
    "# glove data for training - per subject\n",
    "train_dg_s1 = raw_training_data['train_dg'][0][0]\n",
    "train_dg_s2 = raw_training_data['train_dg'][1][0]\n",
    "train_dg_s3 = raw_training_data['train_dg'][2][0]\n",
    "\n",
    "# ecog data for training - per subject\n",
    "train_ecog_s1 = raw_training_data['train_ecog'][0][0]\n",
    "train_ecog_s2 = raw_training_data['train_ecog'][1][0]\n",
    "train_ecog_s3 = raw_training_data['train_ecog'][2][0]\n",
    "\n",
    "# leaderboard ecog signal per patient\n",
    "leaderboard_data_s1 = leaderboard_data['leaderboard_ecog'][0][0]\n",
    "leaderboard_data_s2 = leaderboard_data['leaderboard_ecog'][1][0]\n",
    "leaderboard_data_s3 = leaderboard_data['leaderboard_ecog'][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52b904e-c3fd-43ad-9180-0f1233e555c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete bad channels for subject 1\n",
    "train_ecog_s1 = np.delete(train_ecog_s1,[54],1)\n",
    "leaderboard_data_s1 = np.delete(leaderboard_data_s1,[54],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ce7d02-8b40-4324-adee-d1335ae1f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete bad channels for subject 2\n",
    "train_ecog_s2 = np.delete(train_ecog_s2,[20,37],1)\n",
    "leaderboard_data_s2 = np.delete(leaderboard_data_s2,[20,37],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5eb8c01-7b5d-42bc-af20-65a48b669ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of windows in signal given winLen and winDisp\n",
    "def NumWins(x, fs, winLen, winDisp):\n",
    "    return (len(x) - winLen * fs + winDisp * fs) // (winDisp * fs)\n",
    "\n",
    "\n",
    "def filter_data(raw_eeg, fs=1000):\n",
    "    \"\"\"\n",
    "    Write a filter function to clean underlying data.\n",
    "    Filter type and parameters are up to you. Points will be awarded for reasonable filter type, parameters and application.\n",
    "    Please note there are many acceptable answers, but make sure you aren't throwing out crucial data or adversly\n",
    "    distorting the underlying data!\n",
    "\n",
    "    Input:\n",
    "      raw_eeg (samples x channels): the raw signal\n",
    "      fs: the sampling rate (1000 for this dataset)\n",
    "    Output:\n",
    "      clean_data (samples x channels): the filtered signal\n",
    "    \"\"\"\n",
    "    raw_eeg_t = raw_eeg.transpose()\n",
    "    filtered = []\n",
    "\n",
    "    nyq = fs / 2\n",
    "\n",
    "    # (b, a) = ellip(4, 0.1, 40, 20/nyq, btype='lowpass')\n",
    "    sos = butter(8, [0.15, 200], btype='bandpass', output='sos', fs=fs)\n",
    "\n",
    "    for ch_data in raw_eeg_t:\n",
    "        # filtered_ch = filtfilt(b, a, ch_data)\n",
    "        filtered_ch = sosfiltfilt(sos, ch_data)\n",
    "        filtered.append(filtered_ch)\n",
    "\n",
    "    filtered = np.array(filtered)\n",
    "\n",
    "    return filtered.transpose()\n",
    "\n",
    "\n",
    "# line length\n",
    "def LL(x):\n",
    "    return np.sum(np.absolute(np.ediff1d(x)))\n",
    "\n",
    "\n",
    "# energy\n",
    "def E(x):\n",
    "    return np.sum(x ** 2)\n",
    "\n",
    "#RMS\n",
    "def RMS(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "\n",
    "# area\n",
    "def A(x):\n",
    "    return np.sum(np.absolute(x))\n",
    "\n",
    "\n",
    "# spectral amp\n",
    "def spectral_amplitude(x):\n",
    "    x_fft = np.fft.fft(x)\n",
    "    return np.mean(x_fft)\n",
    "\n",
    "\n",
    "# number of crossings (zero) - not in\n",
    "def ZX(x):\n",
    "    x_demean = x - np.mean(x)\n",
    "    num_crossings = 0\n",
    "    for i in range(1, len(x)):\n",
    "        fromAbove = False\n",
    "        fromBelow = False\n",
    "        if x_demean[i - 1] > 0 and x_demean[i] < 0:\n",
    "            fromAbove = True\n",
    "        if x_demean[i - 1] < 0 and x_demean[i] > 0:\n",
    "            fromBelow = True\n",
    "\n",
    "        if fromAbove or fromBelow:\n",
    "            num_crossings += 1\n",
    "    return num_crossings\n",
    "\n",
    "\n",
    "def bandpower(x, fs, fmin, fmax):\n",
    "    f, Pxx = sig.periodogram(x, fs=fs)\n",
    "    ind_min = np.argmax(f > fmin) - 1\n",
    "    ind_max = np.argmax(f > fmax) - 1\n",
    "    return np.trapz(Pxx[ind_min: ind_max], f[ind_min: ind_max])\n",
    "\n",
    "\n",
    "# gets features, load features you want calculated from here\n",
    "def get_features(filtered_window, fs=1000):\n",
    "    \"\"\"\n",
    "      Write a function that calculates features for a given filtered window.\n",
    "      Feel free to use features you have seen before in this class, features that\n",
    "      have been used in the literature, or design your own!\n",
    "\n",
    "      Input:\n",
    "        filtered_window (window_samples x channels): the window of the filtered ecog signal\n",
    "        fs: sampling rate\n",
    "      Output:\n",
    "        features (channels x num_features): the features calculated on each channel for the window\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_window_t = filtered_window.transpose()\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for ch in filtered_window_t:\n",
    "        features.append(np.array([RMS(ch),\n",
    "                                  bandpower(ch, fs, 0.5, 4),\n",
    "                                  bandpower(ch, fs, 3, 7),\n",
    "                                  bandpower(ch, fs, 8, 12),\n",
    "                                  bandpower(ch, fs, 12.5, 30),\n",
    "                                  bandpower(ch, fs, 25, 140)\n",
    "                                  ]))\n",
    "\n",
    "    features = np.array(features)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Bandpower, can try specifying the following:\n",
    "# Delta: fmin = 0.5, fmax = 4\n",
    "# Theta: fmin = 4, fmax = 7\n",
    "# Alpha: fmin = 8, fmax = 12\n",
    "# Beta: fmin = 12.5, fmax = 30\n",
    "# Gamma: fmin = 25, fmax = 140\n",
    "# get_windowed_feats - filters raw ecog signal and finds features\n",
    "\n",
    "# From the paper suggestion:\n",
    "# fmin = 5, fmax = 15\n",
    "# fmin = 20, fmax = 25\n",
    "# fmin = 75, fmax = 115\n",
    "# fmin = 125, fmax = 160\n",
    "# fmin = 160, fmax = 175\n",
    "\n",
    "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap):\n",
    "    \"\"\"\n",
    "      Write a function which processes data through the steps of filtering and\n",
    "      feature calculation and returns features. Points will be awarded for completing\n",
    "      each step appropriately (note that if one of the functions you call within this script\n",
    "      returns a bad output, you won't be double penalized). Note that you will need\n",
    "      to run the filter_data and get_features functions within this function.\n",
    "\n",
    "      Inputs:\n",
    "        raw_eeg (samples x channels): the raw signal\n",
    "        fs: the sampling rate (1000 for this dataset)\n",
    "        window_length: the window's length\n",
    "        window_overlap: the window's overlap\n",
    "      Output:\n",
    "        all_feats (num_windows x (channels x features)): the features for each channel for each time window\n",
    "          note that this is a 2D array.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_ecog = filter_data(raw_ecog)\n",
    "    num_wins = NumWins(cleaned_ecog.transpose()[0], fs, window_length, window_overlap)\n",
    "    all_feats_3d = []\n",
    "    for winStart in np.arange(0, int(num_wins), 1):\n",
    "        clip = cleaned_ecog[\n",
    "               int(winStart * window_overlap * fs):int(winStart * window_overlap * fs + (window_length * fs))]\n",
    "        all_feats_3d.append(get_features(clip))\n",
    "\n",
    "    num_channels = len(all_feats_3d[0])\n",
    "    num_features = len(all_feats_3d[0][0])\n",
    "\n",
    "    all_feats = np.zeros([len(all_feats_3d), num_features * num_channels])\n",
    "\n",
    "    for k in range(int(len(all_feats_3d))):\n",
    "        q = flatten_list = [j for sub in all_feats_3d[k] for j in sub]\n",
    "        all_feats[k, :] = q\n",
    "\n",
    "    return np.array(all_feats)\n",
    "\n",
    "def repeat_preds(preds, window_to_time_ratio=50):\n",
    "    pred_all = []\n",
    "    for row in preds:\n",
    "        for i in range(window_to_time_ratio):\n",
    "            pred_all.append(row)\n",
    "\n",
    "    # For out problem, it is short 50 entries, so add the last row 50 more times\n",
    "    for i in range(window_to_time_ratio):\n",
    "        pred_all.append(row)\n",
    "    \n",
    "    return np.array(pred_all)\n",
    "\n",
    "def interp_preds(preds, time_length):\n",
    "    # N samples\n",
    "    preds_sample_orig = np.arange(len(preds))\n",
    "    \n",
    "    # T time points\n",
    "    preds_sample_target = np.arange(time_length)\n",
    "    \n",
    "    preds = preds.transpose()\n",
    "\n",
    "    preds_interp = []\n",
    "    \n",
    "    for finger_preds in preds:\n",
    "        f = interp1d(preds_sample_orig, finger_preds)\n",
    "        new_preds = f(preds_sample_target)\n",
    "        preds_interp.append(new_preds)\n",
    "    \n",
    "    preds_interp = np.array(preds_interp).transpose()\n",
    "    \n",
    "    return preds_interp\n",
    "\n",
    "def spline_preds(preds, time_length):\n",
    "    # N samples\n",
    "    preds_sample_orig = np.arange(len(preds))\n",
    "    \n",
    "    # T time points\n",
    "    preds_sample_target = np.linspace(0,len(preds),time_length)\n",
    "    print(preds_sample_target)\n",
    "    preds = preds.transpose()\n",
    "\n",
    "    preds_interp = []\n",
    "    \n",
    "    for finger_preds in preds:\n",
    "        f = CubicSpline(preds_sample_orig, finger_preds, bc_type='natural')\n",
    "        new_preds = f(preds_sample_target)\n",
    "        preds_interp.append(new_preds)\n",
    "    \n",
    "    preds_interp = np.array(preds_interp).transpose()\n",
    "    \n",
    "    return preds_interp\n",
    "\n",
    "def compute_corr(preds, truth):\n",
    "    subj_corr = []\n",
    "    for i in range(5):\n",
    "        finger_pred = preds.transpose()[i]\n",
    "        finger_truth = truth.transpose()[i]\n",
    "        subj_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "    \n",
    "    return subj_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93dd2b8a-f5bb-4c3f-afbd-78b6c541b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats_s1 = get_windowed_feats(train_ecog_s1, 1000, 0.1, 0.05)  # output of get_windowed_feats\n",
    "all_feats_s2 = get_windowed_feats(train_ecog_s2, 1000, 0.1, 0.05)\n",
    "all_feats_s3 = get_windowed_feats(train_ecog_s3, 1000, 0.1, 0.05)\n",
    "\n",
    "feats_LB_s1 = get_windowed_feats(leaderboard_data_s1, 1000, 0.1, 0.05)\n",
    "feats_LB_s2 = get_windowed_feats(leaderboard_data_s2, 1000, 0.1, 0.05)\n",
    "feats_LB_s3 = get_windowed_feats(leaderboard_data_s3, 1000, 0.1, 0.05)\n",
    "\n",
    "train_dg_s1_downsample = train_dg_s1[::50][:-1]\n",
    "train_dg_s2_downsample = train_dg_s2[::50][:-1]\n",
    "train_dg_s3_downsample = train_dg_s3[::50][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21824700-20d9-424c-96d9-502fad9e25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split 0.2/0.8 ecog and downsampled glove data\n",
    "all_feats_train_s1, all_feats_test_s1, T_train_dg_s1_down, test_dg_s1_down = train_test_split(all_feats_s1, train_dg_s1_downsample, test_size=0.2, random_state=24)\n",
    "all_feats_train_s2, all_feats_test_s2, T_train_dg_s2_down, test_dg_s2_down = train_test_split(all_feats_s2, train_dg_s2_downsample, test_size=0.2, random_state=24)\n",
    "all_feats_train_s3, all_feats_test_s3, T_train_dg_s3_down, test_dg_s3_down = train_test_split(all_feats_s3, train_dg_s3_downsample, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eadc40e7-8cc9-45b0-8389-dca580f14d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMS, and bandwidths (natural). I split them beforehand. \n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/all_feats_s1.npy', all_feats_s1)\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/all_feats_s2.npy', all_feats_s2)\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/all_feats_s3.npy', all_feats_s3)\n",
    "\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/feats_LB_s1.npy', feats_LB_s1)\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/feats_LB_s2.npy', feats_LB_s2)\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/feats_LB_s3.npy', feats_LB_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e51395-4c78-4d04-a990-375dc4f2434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2896ea-ea06-4cae-946b-8c0cff9af5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20026996160734234, 0.2908746675075605, 0.21661214365370163, 0.22813869716359408, 0.2504009793929773]\n"
     ]
    }
   ],
   "source": [
    "#Subject 1 - train, test, and LB_data.\n",
    "rfr_reg_s1 = RandomForestRegressor(n_estimators=1000).fit(all_feats_train_s1, T_train_dg_s1_down)\n",
    "pred_test_s1 = rfr_reg_s1.predict(all_feats_test_s1) #test data\n",
    "\n",
    "subj1_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred_test_s1.transpose()[i]\n",
    "    finger_truth = test_dg_s1_down.transpose()[i]\n",
    "    subj1_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj1_corr)\n",
    "\n",
    "model_fname_s1 = '/Users/carlosaguila/PycharmProjects/BE521/results_v3/subject1_rfr_1000.model'\n",
    "pickle.dump(rfr_reg_s1, open(model_fname_s1, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd120198-d243-4f82-8100-4031deae892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38304308513645563, 0.32134119030945335, 0.3711877445105762, 0.3307774585651103, 0.2973171790885112]\n"
     ]
    }
   ],
   "source": [
    "#Subject 2 - train, test, and LB_data.\n",
    "rfr_reg_s2 = RandomForestRegressor(n_estimators=1000).fit(all_feats_train_s2, T_train_dg_s2_down)\n",
    "pred_test_s2 = rfr_reg_s2.predict(all_feats_test_s2) #test data\n",
    "\n",
    "subj2_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred_test_s2.transpose()[i]\n",
    "    finger_truth = test_dg_s2_down.transpose()[i]\n",
    "    subj2_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj2_corr)\n",
    "\n",
    "model_fname_s2 = '/Users/carlosaguila/PycharmProjects/BE521/results_v3/subject2_rfr_1000.model'\n",
    "pickle.dump(rfr_reg_s2, open(model_fname_s2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ca017d-cf69-48f0-a741-ff7e86495241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4301134002241921, 0.3718900229073767, 0.38614543020924463, 0.475693803900348, 0.3900501757997242]\n"
     ]
    }
   ],
   "source": [
    "#Subject 3 - train, test, and LB_data.\n",
    "rfr_reg_s3 = RandomForestRegressor(n_estimators=1000).fit(all_feats_train_s3, T_train_dg_s3_down)\n",
    "pred_test_s3 = rfr_reg_s3.predict(all_feats_test_s3) #test data\n",
    "\n",
    "subj3_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred_test_s3.transpose()[i]\n",
    "    finger_truth = test_dg_s3_down.transpose()[i]\n",
    "    subj3_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj3_corr)\n",
    "\n",
    "model_fname_s3 = '/Users/carlosaguila/PycharmProjects/BE521/results_v3/subject3_rfr_1000.model'\n",
    "pickle.dump(rfr_reg_s3, open(model_fname_s3, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7a020-156a-4768-8002-aed0070f3402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88437c06-6841-4724-a041-d233b31bac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leaderboard data - subject 1\n",
    "LB_pred_s1 = rfr_reg_s1.predict(feats_LB_s1)  # predicting from features from leaderboard data\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/LB_pred_s1.npy', LB_pred_s1)\n",
    "\n",
    "#leaderboard data - subject 2\n",
    "LB_pred_s2 = rfr_reg_s2.predict(feats_LB_s2)  # predicting from features from leaderboard data\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/LB_pred_s2.npy', LB_pred_s2)\n",
    "\n",
    "#leaderboard data - subject 3\n",
    "LB_pred_s3 = rfr_reg_s3.predict(feats_LB_s3)  # predicting from features from leaderboard data\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v3/LB_pred_s3.npy', LB_pred_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aac6cdc-6abf-42ce-89e7-0ffddd85eb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 1.99933559e-02 3.99867118e-02 ... 2.94896001e+03\n",
      " 2.94898001e+03 2.94900000e+03]\n",
      "[0.00000000e+00 1.99933559e-02 3.99867118e-02 ... 2.94896001e+03\n",
      " 2.94898001e+03 2.94900000e+03]\n",
      "[0.00000000e+00 1.99933559e-02 3.99867118e-02 ... 2.94896001e+03\n",
      " 2.94898001e+03 2.94900000e+03]\n"
     ]
    }
   ],
   "source": [
    "#spline for leaderboard predictions\n",
    "pred_s1_test_spline = spline_preds(LB_pred_s1, 147500)\n",
    "pred_s2_test_spline = spline_preds(LB_pred_s2, 147500)\n",
    "pred_s3_test_spline = spline_preds(LB_pred_s3, 147500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65fa34e8-b105-4da5-833c-353f23e76b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147500, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(pred_s1_test_spline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae9986cb-afb0-48cf-b19b-caa8efd7ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "predictions_array = np.zeros((3,1), dtype=object)\n",
    "predictions_array[0,0] = pred_s1_test_spline\n",
    "predictions_array[1,0] = pred_s2_test_spline\n",
    "predictions_array[2,0] = pred_s3_test_spline\n",
    "\n",
    "savemat('/Users/carlosaguila/PycharmProjects/BE521/results_v3/predictions.mat', {'predicted_dg':predictions_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3f132-d107-4d59-a204-6b7c862709cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
