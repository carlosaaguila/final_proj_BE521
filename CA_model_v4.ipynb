{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f018b75-ab8a-4608-a4e8-ea1461179975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import signal as sig\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import ellip, lfilter, filtfilt, find_peaks, butter, sosfiltfilt, sosfilt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "leaderboard_data = loadmat('/Users/carlosaguila/Downloads/drive-download-20220406T170639Z-001/leaderboard_data.mat')\n",
    "raw_training_data = loadmat('/Users/carlosaguila/Downloads/drive-download-20220406T170639Z-001/raw_training_data.mat')\n",
    "\n",
    "# glove data for training - per subject\n",
    "train_dg_s1 = raw_training_data['train_dg'][0][0]\n",
    "train_dg_s2 = raw_training_data['train_dg'][1][0]\n",
    "train_dg_s3 = raw_training_data['train_dg'][2][0]\n",
    "\n",
    "# ecog data for training - per subject\n",
    "train_ecog_s1 = raw_training_data['train_ecog'][0][0]\n",
    "train_ecog_s2 = raw_training_data['train_ecog'][1][0]\n",
    "train_ecog_s3 = raw_training_data['train_ecog'][2][0]\n",
    "\n",
    "# leaderboard ecog signal per patient\n",
    "leaderboard_data_s1 = leaderboard_data['leaderboard_ecog'][0][0]\n",
    "leaderboard_data_s2 = leaderboard_data['leaderboard_ecog'][1][0]\n",
    "leaderboard_data_s3 = leaderboard_data['leaderboard_ecog'][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52b904e-c3fd-43ad-9180-0f1233e555c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete bad channels for subject 1\n",
    "train_ecog_s1 = np.delete(train_ecog_s1,[54],1)\n",
    "leaderboard_data_s1 = np.delete(leaderboard_data_s1,[54],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ce7d02-8b40-4324-adee-d1335ae1f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete bad channels for subject 2\n",
    "train_ecog_s2 = np.delete(train_ecog_s2,[20,37],1)\n",
    "leaderboard_data_s2 = np.delete(leaderboard_data_s2,[20,37],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5eb8c01-7b5d-42bc-af20-65a48b669ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of windows in signal given winLen and winDisp\n",
    "def NumWins(x, fs, winLen, winDisp):\n",
    "    return (len(x) - winLen * fs + winDisp * fs) // (winDisp * fs)\n",
    "\n",
    "\n",
    "def filter_data(raw_eeg, fs=1000):\n",
    "    \"\"\"\n",
    "    Write a filter function to clean underlying data.\n",
    "    Filter type and parameters are up to you. Points will be awarded for reasonable filter type, parameters and application.\n",
    "    Please note there are many acceptable answers, but make sure you aren't throwing out crucial data or adversly\n",
    "    distorting the underlying data!\n",
    "\n",
    "    Input:\n",
    "      raw_eeg (samples x channels): the raw signal\n",
    "      fs: the sampling rate (1000 for this dataset)\n",
    "    Output:\n",
    "      clean_data (samples x channels): the filtered signal\n",
    "    \"\"\"\n",
    "    raw_eeg_t = raw_eeg.transpose()\n",
    "    filtered = []\n",
    "\n",
    "    nyq = fs / 2\n",
    "\n",
    "    # (b, a) = ellip(4, 0.1, 40, 20/nyq, btype='lowpass')\n",
    "    sos = butter(8, [0.15, 200], btype='bandpass', output='sos', fs=fs)\n",
    "\n",
    "    for ch_data in raw_eeg_t:\n",
    "        # filtered_ch = filtfilt(b, a, ch_data)\n",
    "        filtered_ch = sosfiltfilt(sos, ch_data)\n",
    "        filtered.append(filtered_ch)\n",
    "\n",
    "    filtered = np.array(filtered)\n",
    "\n",
    "    return filtered.transpose()\n",
    "\n",
    "\n",
    "# line length\n",
    "def LL(x):\n",
    "    return np.sum(np.absolute(np.ediff1d(x)))\n",
    "\n",
    "\n",
    "# energy\n",
    "def E(x):\n",
    "    return np.sum(x ** 2)\n",
    "\n",
    "#RMS\n",
    "def RMS(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "\n",
    "# area\n",
    "def A(x):\n",
    "    return np.sum(np.absolute(x))\n",
    "\n",
    "\n",
    "# spectral amp\n",
    "def spectral_amplitude(x):\n",
    "    x_fft = np.fft.fft(x)\n",
    "    return np.mean(x_fft)\n",
    "\n",
    "def mean_amplitude_freq(X, fs, lF, uF):\n",
    "    time_step = 1/fs\n",
    "    ps = np.abs(np.fft.fft(X)) ** 2\n",
    "    freqs = np.fft.fftfreq(X.size, time_step)\n",
    "    mask = np.logical_and(freqs >= lF, freqs <= uF )\n",
    "    avgValue = ps[mask].mean()\n",
    "    return avgValue\n",
    "\n",
    "# number of crossings (zero) - not in\n",
    "def ZX(x):\n",
    "    x_demean = x - np.mean(x)\n",
    "    num_crossings = 0\n",
    "    for i in range(1, len(x)):\n",
    "        fromAbove = False\n",
    "        fromBelow = False\n",
    "        if x_demean[i - 1] > 0 and x_demean[i] < 0:\n",
    "            fromAbove = True\n",
    "        if x_demean[i - 1] < 0 and x_demean[i] > 0:\n",
    "            fromBelow = True\n",
    "\n",
    "        if fromAbove or fromBelow:\n",
    "            num_crossings += 1\n",
    "    return num_crossings\n",
    "\n",
    "def MEAN(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "def bandpower(x, fs, fmin, fmax):\n",
    "    f, Pxx = sig.periodogram(x, fs=fs)\n",
    "    ind_min = np.argmax(f > fmin) - 1\n",
    "    ind_max = np.argmax(f > fmax) - 1\n",
    "    return np.trapz(Pxx[ind_min: ind_max], f[ind_min: ind_max])\n",
    "\n",
    "# gets features, load features you want calculated from here\n",
    "def get_features(filtered_window, fs=1000):\n",
    "    \"\"\"\n",
    "      Write a function that calculates features for a given filtered window.\n",
    "      Feel free to use features you have seen before in this class, features that\n",
    "      have been used in the literature, or design your own!\n",
    "\n",
    "      Input:\n",
    "        filtered_window (window_samples x channels): the window of the filtered ecog signal\n",
    "        fs: sampling rate\n",
    "      Output:\n",
    "        features (channels x num_features): the features calculated on each channel for the window\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_window_t = filtered_window.transpose()\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for ch in filtered_window_t:\n",
    "        features.append(np.array([MEAN(ch),\n",
    "                                  mean_amplitude_freq(ch, fs, 5, 15),\n",
    "                                  mean_amplitude_freq(ch, fs, 20, 25),\n",
    "                                  mean_amplitude_freq(ch, fs, 75, 115),\n",
    "                                  mean_amplitude_freq(ch, fs, 125, 160),\n",
    "                                  mean_amplitude_freq(ch, fs, 160, 175)\n",
    "                                  ]))\n",
    "\n",
    "    features = np.array(features)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Bandpower, can try specifying the following:\n",
    "# Delta: fmin = 0.5, fmax = 4\n",
    "# Theta: fmin = 4, fmax = 7\n",
    "# Alpha: fmin = 8, fmax = 12\n",
    "# Beta: fmin = 12.5, fmax = 30\n",
    "# Gamma: fmin = 25, fmax = 140\n",
    "# get_windowed_feats - filters raw ecog signal and finds features\n",
    "\n",
    "# From the paper suggestion:\n",
    "# fmin = 5, fmax = 15\n",
    "# fmin = 20, fmax = 25\n",
    "# fmin = 75, fmax = 115\n",
    "# fmin = 125, fmax = 160\n",
    "# fmin = 160, fmax = 175\n",
    "\n",
    "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap):\n",
    "    \"\"\"\n",
    "      Write a function which processes data through the steps of filtering and\n",
    "      feature calculation and returns features. Points will be awarded for completing\n",
    "      each step appropriately (note that if one of the functions you call within this script\n",
    "      returns a bad output, you won't be double penalized). Note that you will need\n",
    "      to run the filter_data and get_features functions within this function.\n",
    "\n",
    "      Inputs:\n",
    "        raw_eeg (samples x channels): the raw signal\n",
    "        fs: the sampling rate (1000 for this dataset)\n",
    "        window_length: the window's length\n",
    "        window_overlap: the window's overlap\n",
    "      Output:\n",
    "        all_feats (num_windows x (channels x features)): the features for each channel for each time window\n",
    "          note that this is a 2D array.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_ecog = filter_data(raw_ecog)\n",
    "    num_wins = NumWins(cleaned_ecog.transpose()[0], fs, window_length, window_overlap)\n",
    "    all_feats_3d = []\n",
    "    for winStart in np.arange(0, int(num_wins), 1):\n",
    "        clip = cleaned_ecog[\n",
    "               int(winStart * window_overlap * fs):int(winStart * window_overlap * fs + (window_length * fs))]\n",
    "        all_feats_3d.append(get_features(clip))\n",
    "\n",
    "    num_channels = len(all_feats_3d[0])\n",
    "    num_features = len(all_feats_3d[0][0])\n",
    "\n",
    "    all_feats = np.zeros([len(all_feats_3d), num_features * num_channels])\n",
    "\n",
    "    for k in range(int(len(all_feats_3d))):\n",
    "        q = flatten_list = [j for sub in all_feats_3d[k] for j in sub]\n",
    "        all_feats[k, :] = q\n",
    "\n",
    "    return np.array(all_feats)\n",
    "\n",
    "def repeat_preds(preds, window_to_time_ratio=50):\n",
    "    pred_all = []\n",
    "    for row in preds:\n",
    "        for i in range(window_to_time_ratio):\n",
    "            pred_all.append(row)\n",
    "\n",
    "    # For out problem, it is short 50 entries, so add the last row 50 more times\n",
    "    for i in range(window_to_time_ratio):\n",
    "        pred_all.append(row)\n",
    "    \n",
    "    return np.array(pred_all)\n",
    "\n",
    "def interp_preds(preds, time_length):\n",
    "    # N samples\n",
    "    preds_sample_orig = np.arange(len(preds))\n",
    "    \n",
    "    # T time points\n",
    "    preds_sample_target = np.arange(time_length)\n",
    "    \n",
    "    preds = preds.transpose()\n",
    "\n",
    "    preds_interp = []\n",
    "    \n",
    "    for finger_preds in preds:\n",
    "        f = interp1d(preds_sample_orig, finger_preds)\n",
    "        new_preds = f(preds_sample_target)\n",
    "        preds_interp.append(new_preds)\n",
    "    \n",
    "    preds_interp = np.array(preds_interp).transpose()\n",
    "    \n",
    "    return preds_interp\n",
    "\n",
    "def spline_preds(preds, time_length):\n",
    "    # N samples\n",
    "    preds_sample_orig = np.arange(len(preds))\n",
    "    \n",
    "    # T time points\n",
    "    preds_sample_target = np.linspace(0,len(preds),time_length)\n",
    "    print(preds_sample_target)\n",
    "    preds = preds.transpose()\n",
    "\n",
    "    preds_interp = []\n",
    "    \n",
    "    for finger_preds in preds:\n",
    "        f = CubicSpline(preds_sample_orig, finger_preds, bc_type='natural')\n",
    "        new_preds = f(preds_sample_target)\n",
    "        preds_interp.append(new_preds)\n",
    "    \n",
    "    preds_interp = np.array(preds_interp).transpose()\n",
    "    \n",
    "    return preds_interp\n",
    "\n",
    "def compute_corr(preds, truth):\n",
    "    subj_corr = []\n",
    "    for i in range(5):\n",
    "        finger_pred = preds.transpose()[i]\n",
    "        finger_truth = truth.transpose()[i]\n",
    "        subj_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "    \n",
    "    return subj_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93dd2b8a-f5bb-4c3f-afbd-78b6c541b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats_s1 = get_windowed_feats(train_ecog_s1, 1000, 0.1, 0.05)  # output of get_windowed_feats\n",
    "all_feats_s2 = get_windowed_feats(train_ecog_s2, 1000, 0.1, 0.05)\n",
    "all_feats_s3 = get_windowed_feats(train_ecog_s3, 1000, 0.1, 0.05)\n",
    "\n",
    "feats_LB_s1 = get_windowed_feats(leaderboard_data_s1, 1000, 0.1, 0.05)\n",
    "feats_LB_s2 = get_windowed_feats(leaderboard_data_s2, 1000, 0.1, 0.05)\n",
    "feats_LB_s3 = get_windowed_feats(leaderboard_data_s3, 1000, 0.1, 0.05)\n",
    "\n",
    "train_dg_s1_downsample = train_dg_s1[::50][:-1]\n",
    "train_dg_s2_downsample = train_dg_s2[::50][:-1]\n",
    "train_dg_s3_downsample = train_dg_s3[::50][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21824700-20d9-424c-96d9-502fad9e25a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split 0.2/0.8 ecog and downsampled glove data\n",
    "all_feats_train_s1, all_feats_test_s1, T_train_dg_s1_down, test_dg_s1_down = train_test_split(all_feats_s1, train_dg_s1_downsample, test_size=0.2, random_state=24)\n",
    "all_feats_train_s2, all_feats_test_s2, T_train_dg_s2_down, test_dg_s2_down = train_test_split(all_feats_s2, train_dg_s2_downsample, test_size=0.2, random_state=24)\n",
    "all_feats_train_s3, all_feats_test_s3, T_train_dg_s3_down, test_dg_s3_down = train_test_split(all_feats_s3, train_dg_s3_downsample, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadc40e7-8cc9-45b0-8389-dca580f14d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean voltage, and mean amplitude from bandwidths\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/all_feats_s1.npy', all_feats_s1)\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/all_feats_s2.npy', all_feats_s2)\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/all_feats_s3.npy', all_feats_s3)\n",
    "\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/feats_LB_s1.npy', feats_LB_s1)\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/feats_LB_s2.npy', feats_LB_s2)\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/feats_LB_s3.npy', feats_LB_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e51395-4c78-4d04-a990-375dc4f2434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e2896ea-ea06-4cae-946b-8c0cff9af5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24007872490208715, 0.30260916710112473, 0.1994356223060803, 0.3328618566023698, 0.19028522095005912]\n"
     ]
    }
   ],
   "source": [
    "#Subject 1 - train, test, and LB_data.\n",
    "rfr_reg_s1 = RandomForestRegressor(n_estimators=1000).fit(all_feats_train_s1, T_train_dg_s1_down)\n",
    "pred_test_s1 = rfr_reg_s1.predict(all_feats_test_s1) #test data\n",
    "\n",
    "subj1_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred_test_s1.transpose()[i]\n",
    "    finger_truth = test_dg_s1_down.transpose()[i]\n",
    "    subj1_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj1_corr)\n",
    "\n",
    "model_fname_s1 = '/Users/carlosaguila/PycharmProjects/BE521/results_v4/subject1_rfr_1000.model'\n",
    "pickle.dump(rfr_reg_s1, open(model_fname_s1, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd120198-d243-4f82-8100-4031deae892c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j3/ps9_bddj0kg0ds3px8t769_00000gn/T/ipykernel_70039/704090505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Subject 2 - train, test, and LB_data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfr_reg_s2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_feats_train_s2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_train_dg_s2_down\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_test_s2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfr_reg_s2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_feats_test_s2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubj2_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \"\"\"\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1253\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Subject 2 - train, test, and LB_data.\n",
    "rfr_reg_s2 = RandomForestRegressor(n_estimators=1000).fit(all_feats_train_s2, T_train_dg_s2_down)\n",
    "pred_test_s2 = rfr_reg_s2.predict(all_feats_test_s2) #test data\n",
    "\n",
    "subj2_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred_test_s2.transpose()[i]\n",
    "    finger_truth = test_dg_s2_down.transpose()[i]\n",
    "    subj2_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj2_corr)\n",
    "\n",
    "model_fname_s2 = '/Users/carlosaguila/PycharmProjects/BE521/results_v4/subject2_rfr_1000.model'\n",
    "pickle.dump(rfr_reg_s2, open(model_fname_s2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca017d-cf69-48f0-a741-ff7e86495241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subject 3 - train, test, and LB_data.\n",
    "rfr_reg_s3 = RandomForestRegressor(n_estimators=1000).fit(all_feats_train_s3, T_train_dg_s3_down)\n",
    "pred_test_s3 = rfr_reg_s3.predict(all_feats_test_s3) #test data\n",
    "\n",
    "subj3_corr = []\n",
    "for i in range(5):\n",
    "    finger_pred = pred_test_s3.transpose()[i]\n",
    "    finger_truth = test_dg_s3_down.transpose()[i]\n",
    "    subj3_corr.append(pearsonr(finger_pred, finger_truth)[0])\n",
    "\n",
    "print(subj3_corr)\n",
    "\n",
    "model_fname_s3 = '/Users/carlosaguila/PycharmProjects/BE521/results_v4/subject3_rfr_1000.model'\n",
    "pickle.dump(rfr_reg_s3, open(model_fname_s3, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7a020-156a-4768-8002-aed0070f3402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88437c06-6841-4724-a041-d233b31bac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leaderboard data - subject 1\n",
    "LB_pred_s1 = rfr_reg_s1.predict(feats_LB_s1)  # predicting from features from leaderboard data\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/LB_pred_s1.npy', LB_pred_s1)\n",
    "\n",
    "#leaderboard data - subject 2\n",
    "LB_pred_s2 = rfr_reg_s2.predict(feats_LB_s2)  # predicting from features from leaderboard data\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/LB_pred_s2.npy', LB_pred_s2)\n",
    "\n",
    "#leaderboard data - subject 3\n",
    "LB_pred_s3 = rfr_reg_s3.predict(feats_LB_s3)  # predicting from features from leaderboard data\n",
    "np.save('/Users/carlosaguila/PycharmProjects/BE521/results_v4/LB_pred_s3.npy', LB_pred_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac6cdc-6abf-42ce-89e7-0ffddd85eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spline for leaderboard predictions\n",
    "pred_s1_test_spline = spline_preds(LB_pred_s1, 147500)\n",
    "pred_s2_test_spline = spline_preds(LB_pred_s2, 147500)\n",
    "pred_s3_test_spline = spline_preds(LB_pred_s3, 147500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9986cb-afb0-48cf-b19b-caa8efd7ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "predictions_array = np.zeros((3,1), dtype=object)\n",
    "predictions_array[0,0] = pred_s1_test_spline\n",
    "predictions_array[1,0] = pred_s2_test_spline\n",
    "predictions_array[2,0] = pred_s3_test_spline\n",
    "\n",
    "savemat('/Users/carlosaguila/PycharmProjects/BE521/results_v4/predictions.mat', {'predicted_dg':predictions_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c4ecb-b508-4b0f-9202-24cf1db7f730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
